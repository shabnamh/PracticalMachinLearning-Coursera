---
title: "Predicting the Manner Exercise was Done!"
output: html_document
---

##Introducing the Data
The data consists of accelerometer measurements of 6 male participants lifting barbell in five different ways while four accelerometrs record them. There are fives classes in the data set, class A is the correct manner and classes B to E each represent a mistake in lifting the barbell.

The goal is to use the accelerometer measurements gathered on belt, forearm, arm,and dumbbell and predict  which class the barbell lift data belongs to (in which manner this activity was performed)

##Data Cleaning and Exploratory Analysis
```{r}
library(caret); library(ggplot2)
```
```{r}
Training <- read.csv("pml-training.csv")
Testing <- read.csv("pml-testing.csv")

#subsetting the training set into training and testing data sets
inTrain <- createDataPartition(y = Training$classe, p= 0.7, list = FALSE)
training <- Training[inTrain,]
testing <- Training[ -inTrain, ]
dim(training)
dim(testing)
```

First, variables with the Near Zero Variance are removed.

```{r}
nzv <- nearZeroVar(training, saveMetrics = TRUE)
training <- training[,nzv$nzv == FALSE]
testing <- testing[,nzv$nzv == FALSE]
```

Second, variables that have mostly NA values are removed.

```{r}
mNA <- sapply(training, function(x) mean(is.na(x))) > 0.95
training <- training[, mNA == FALSE]
testing <- testing[, mNA == FALSE]
```

Finally, the first five columns that are identification columns and not needed for prediction are removed.

```{r}
training <- training[, -(1:5)]
testing <- testing[, -(1:5)]
```

##The Model
###Model 1
I decided to use the **Random Forest** as the fitting method and 3-fold cross validation to select optimal tuning parameters for the model.

```{r}
set.seed(1235)
#to set train function to use 3-fold cv for cross validation
fitControl <- trainControl(method = "cv", number = 3, verboseIter = F)

mod1 <- train(classe ~. , method = "rf", data = training, trControl = fitControl)
mod1$finalModel

pred1 <- predict(mod1, testing)
confMat1 <- confusionMatrix(pred1, testing$classe)
confMat1

plot(confMat1$table, col= confMat1$byClass, main = paste("Random Forest Result- Accuracy = ", round(confMat1$overall['Accuracy'], 4)))
```

The random forest gives an overall accuracy of `r 100 * (round(confMat1$overall['Accuracy'], 4))`% and out of sample error rate of `r 100 - 100 * (round(confMat1$overall['Accuracy'], 4))`%. Random Forest seems to be a great choice, however I will try to the generalized boosted model as well to compare.

###Model 2
I am going to apply **Generalized Boosted Regression Model** as well with the same cross validation method and see how it compares with Random Forest.

```{r, results= "hide"}
set.seed(1235)
mod2 <- train(classe ~. , method = "gbm", data = training, trControl = fitControl)
```
```{r}
mod2$finalModel

pred2 <- predict(mod2, testing)
confMat2 <- confusionMatrix(pred2, testing$classe)
confMat2

plot(confMat2$table, col= confMat2$byClass, main = paste("General Boosted Regression Model Result- Accuracy = ", round(confMat2$overall['Accuracy'], 4)))
```

The Generalized Boosted Regression Model has an accuracy of `r 100 * (round(confMat2$overall['Accuracy'], 4))`% and out of sample error rate of `r 100 - 100 * (round(confMat2$overall['Accuracy'], 4))`%. 

###Chosen Model
**Random Forest** has a higher accuracy in predicting and is the model I'm going to apply to testing data set.

##Applying the prediction model to the Test data set
```{r}
predT <- predict(mod1, newdata = Testing)
predT
```
